{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2 Mid-level API: Demonstration\n",
    "\n",
    "The examples below use mid-level APIs in TensorFlow to implement a linear regression model.\n",
    "\n",
    "Mid-level API includes model layers, loss functions, optimizers, data pipelines, feature columns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,losses,metrics,optimizers\n",
    "\n",
    "\n",
    "# Print time stamps\n",
    "@tf.function\n",
    "def printbar():\n",
    "    ts = tf.timestamp()\n",
    "    today_ts = ts%(24*60*60)\n",
    "\n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n",
    "    minite = tf.cast((today_ts%3600)//60,tf.int32)\n",
    "    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n",
    "    \n",
    "    def timeformat(m):\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n",
    "            return(tf.strings.format(\"0{}\",m))\n",
    "        else:\n",
    "            return(tf.strings.format(\"{}\",m))\n",
    "    \n",
    "    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n",
    "                timeformat(second)],separator = \":\")\n",
    "    tf.print(\"==========\"*8,end = \"\")\n",
    "    tf.print(timestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "n = 800\n",
    "\n",
    "# Generate testing dataset\n",
    "X = tf.random.uniform([n,2],minval=-10,maxval=10) \n",
    "w0 = tf.constant([[2.0],[-1.0]])\n",
    "b0 = tf.constant(3.0)\n",
    "Y = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @ represents matrix multiplication; add Gaussian noise\n",
    "\n",
    "# Creating pipeline of input data\n",
    "ds = tf.data.Dataset.from_tensor_slices((X,Y)) \\\n",
    "     .shuffle(buffer_size = 1000).batch(100) \\\n",
    "     .prefetch(tf.data.experimental.AUTOTUNE)  \n",
    "\n",
    "# Defining optimizer\n",
    "optimizer = optimizers.SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================16:28:49\n",
      "epoch = 100 loss = 6.13818932\n",
      "w = [[2.00223255]\n",
      " [-1.01345801]]\n",
      "b = [2.41117597]\n",
      "\n",
      "================================================================================16:28:52\n",
      "epoch = 200 loss = 5.00730753\n",
      "w = [[2.00545073]\n",
      " [-1.0149585]]\n",
      "b = [2.9106]\n",
      "\n",
      "================================================================================16:28:54\n",
      "epoch = 300 loss = 5.12224627\n",
      "w = [[2.00464392]\n",
      " [-1.01466823]]\n",
      "b = [3.0112443]\n",
      "\n",
      "================================================================================16:28:57\n",
      "epoch = 400 loss = 3.67764401\n",
      "w = [[2.00470614]\n",
      " [-1.01397789]]\n",
      "b = [3.03155828]\n",
      "\n",
      "================================================================================16:28:59\n",
      "epoch = 500 loss = 5.27416801\n",
      "w = [[2.00681973]\n",
      " [-1.0149914]]\n",
      "b = [3.03578353]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear = layers.Dense(units = 1)\n",
    "linear.build(input_shape = (2,)) \n",
    "\n",
    "@tf.function\n",
    "def train(epoches):\n",
    "    for epoch in tf.range(1,epoches+1):\n",
    "        L = tf.constant(0.0) # L is used for recording loss values\n",
    "        for X_batch,Y_batch in ds:\n",
    "            with tf.GradientTape() as tape:\n",
    "                Y_hat = linear(X_batch)\n",
    "                loss = losses.mean_squared_error(tf.reshape(Y_hat,[-1]),tf.reshape(Y_batch,[-1]))\n",
    "            grads = tape.gradient(loss,linear.variables)\n",
    "            optimizer.apply_gradients(zip(grads,linear.variables))\n",
    "            L = loss\n",
    "        \n",
    "        if(epoch%100==0):\n",
    "            printbar()\n",
    "            tf.print(\"epoch =\",epoch,\"loss =\",L)\n",
    "            tf.print(\"w =\",linear.kernel)\n",
    "            tf.print(\"b =\",linear.bias)\n",
    "            tf.print(\"\")\n",
    "\n",
    "train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
